{
  "appTitle": "⚡ Energy Prompt Ninja ⚡",
  "startScreenTitle": "Welcome!",
  "startGameBtn": "Start Game",
  "instructionsBtn": "Instructions",
  "educationBtn": "Learn More",
  "instructionsScreenTitle": "How to Play",
  "backBtn": "Back",
  "summaryScreenTitle": "Game Over!",
  "summaryScorePrefix": "Score:",
  "playAgainBtn": "Play Again",
  "educationScreenTitle": "Learn About Energy & Prompts",
  "promptPlaceholder": "Enter your zero-shot prompt here...",
  "submitBtn": "Submit",
  "langEn": "English",
  "langPl": "Polski",
  "instructionsP1": "Welcome, Energy Prompt Ninja! You are an Energy Prompt Engineer for the Global Energy Transformation Initiative (GETI).",
  "instructionsP2": "Your mission is to craft effective prompts to solve real-world energy problems, optimize systems, and drive innovation in sustainable energy.",
  "instructionsP3": "Use the prompt input area on the game screen to submit your solutions (prompts) to the various energy transformation challenges presented. Good luck!",
  "educationP1Title": "What is a Prompt?",
  "educationP1Text": "A text prompt (sometimes with images) is the input a large language model (LLM) uses to predict an output. You don't need to be a data scientist – everyone can write a prompt!",
  "educationP2Title": "What is Prompt Engineering?",
  "educationP2Text": "Crafting effective prompts can be complex. Aspects like the model used, its training data, configuration, your word choice, style, tone, structure, and context all matter. Prompt engineering is the iterative process of designing high-quality prompts to guide LLMs towards accurate and meaningful outputs. It involves tinkering to find the best prompt, optimizing length, and evaluating its style and structure.",
  "educationP3Text": "Remember, an LLM is a prediction engine. It takes text and predicts the next word (token) based on its training. Your prompt sets up the LLM to predict the right sequence of tokens.",
  "educationP4Title": "Few-Shot Prompting:",
  "educationP4Text": "When zero-shot isn't enough, you can provide multiple examples (shots) in your prompt. This shows the model a specific pattern or output structure you want it to follow. Useful for more complex tasks or when you need precise output formatting.",
  "educationP5Title": "Role Prompting:",
  "educationP5Text": "Assign a specific role or persona to the LLM (e.g., \"Act as a solar energy expert\", \"You are a helpful assistant explaining grid stability\"). This helps the model adopt the knowledge, tone, and style associated with that role, leading to more focused and contextually appropriate responses.",
  "educationP6Title": "System Prompting:",
  "educationP6Text": "Set overall rules or constraints for the LLM's behavior (e.g., \"Only return JSON\", \"Answer in a formal tone\"). This helps control the output format, enforce safety guidelines, or define the model's overall task boundaries.",
  "educationP7Title": "Contextual Prompting:",
  "educationP7Text": "Provide specific background information or context relevant to the immediate task (e.g., \"Context: The user is asking about solar panel efficiency in cloudy weather.\"). This helps the model generate more relevant and nuanced responses.",
  "educationP8Title": "Step-Back Prompting:",
  "educationP8Text": "Ask a broader, more general question first to activate relevant concepts, then use that answer as context for your specific question. Helps the LLM apply general principles to solve complex problems.",
  "educationP9Title": "Chain of Thought (CoT):",
  "educationP9Text": "Prompt the LLM to explain its reasoning step-by-step before giving the final answer (e.g., add \"Let's think step by step.\"). Improves performance on tasks requiring logic, calculation, or multi-step deduction.",
  "educationP10Title": "Self-Consistency:",
  "educationP10Text": "Generate multiple chains of thought for the same prompt (often using higher temperature) and choose the most frequent final answer. Improves robustness and accuracy, especially for complex reasoning tasks.",
  "educationP11Title": "Tree of Thoughts (ToT):",
  "educationP11Text": "Allows the LLM to explore multiple reasoning paths simultaneously, evaluating intermediate steps like branches on a tree. Useful for very complex problems requiring exploration and strategic thinking.",
  "summaryText": "Summary of your game goes here..."
}
