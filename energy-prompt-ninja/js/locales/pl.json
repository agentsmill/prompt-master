{
  "appTitle": "⚡ Ninja Energetycznych Promptów ⚡",
  "startScreenTitle": "Witaj!",
  "startGameBtn": "Rozpocznij Grę",
  "instructionsBtn": "Instrukcje",
  "educationBtn": "Dowiedz się Więcej",
  "instructionsScreenTitle": "Jak Grać",
  "backBtn": "Powrót",
  "summaryScreenTitle": "Koniec Gry!",
  "summaryScorePrefix": "Wynik:",
  "playAgainBtn": "Zagraj Ponownie",
  "educationScreenTitle": "Dowiedz się o Energii i Promptach",
  "promptPlaceholder": "Wpisz tutaj swój prompt zero-shot...",
  "submitBtn": "Wyślij",
  "langEn": "English",
  "langPl": "Polski",
  "instructionsP1": "Witaj, Ninja Energetycznych Promptów! Jesteś Inżynierem Promptów Energetycznych w Globalnej Inicjatywie Transformacji Energetycznej (GETI).",
  "instructionsP2": "Twoją misją jest tworzenie skutecznych promptów, aby rozwiązywać rzeczywiste problemy energetyczne, optymalizować systemy i napędzać innowacje w zrównoważonych technologiach energetycznych.",
  "instructionsP3": "Użyj pola wprowadzania promptów na ekranie gry, aby przesyłać swoje rozwiązania (prompty) do różnych wyzwań transformacji energetycznej. Powodzenia!",
  "educationP1Title": "Co to jest Prompt?",
  "educationP1Text": "Prompt tekstowy (czasami z obrazkami) to dane wejściowe, których duży model językowy (LLM) używa do przewidywania określonych danych wyjściowych. Nie musisz być analitykiem danych – każdy może napisać prompt!",
  "educationP2Title": "Co to jest Inżynieria Promptów?",
  "educationP2Text": "Tworzenie skutecznych promptów może być złożone. Aspekty takie jak używany model, jego dane treningowe, konfiguracja, dobór słów, styl, ton, struktura i kontekst mają znaczenie. Inżynieria promptów to iteracyjny proces projektowania wysokiej jakości promptów, które kierują LLM w stronę dokładnych i znaczących odpowiedzi. Obejmuje eksperymentowanie w celu znalezienia najlepszego promptu, optymalizację długości i ocenę jego stylu oraz struktury.",
  "educationP3Text": "Pamiętaj, LLM to silnik predykcyjny. Pobiera tekst i przewiduje następne słowo (token) na podstawie danych treningowych. Twój prompt przygotowuje LLM do przewidzenia właściwej sekwencji tokenów.",
  "educationP4Title": "Prompting Few-Shot:",
  "educationP4Text": "Gdy zero-shot nie wystarcza, możesz podać wiele przykładów (shots) w swoim prompcie. Pokazuje to modelowi konkretny wzorzec lub strukturę wyjściową, którą ma naśladować. Przydatne przy bardziej złożonych zadaniach lub gdy potrzebujesz precyzyjnego formatowania wyjściowego.",
  "educationP5Title": "Prompting z Rolą:",
  "educationP5Text": "Przypisz określoną rolę lub postać do LLM (np. 'Działaj jako ekspert ds. energii słonecznej', 'Jesteś pomocnym asystentem wyjaśniającym stabilność sieci'). Pomaga to modelowi przyjąć wiedzę, ton i styl związane z tą rolą, prowadząc do bardziej ukierunkowanych i kontekstowo odpowiednich odpowiedzi.",
  "educationP6Title": "Prompting Systemowy:",
  "educationP6Text": "Ustaw ogólne zasady lub ograniczenia dla zachowania LLM (np. 'Zwracaj tylko JSON', 'Odpowiadaj w formalnym tonie'). Pomaga to kontrolować format wyjściowy, egzekwować wytyczne bezpieczeństwa lub definiować ogólne granice zadania modelu.",
  "educationP7Title": "Prompting Kontekstowy:",
  "educationP7Text": "Podaj konkretne informacje ogólne lub kontekst relevantny dla bieżącego zadania (np. 'Kontekst: Użytkownik pyta o wydajność paneli słonecznych przy zachmurzeniu.'). Pomaga to modelowi generować bardziej trafne i zniuansowane odpowiedzi.",
  "educationP8Title": "Prompting Step-Back:",
  "educationP8Text": "Zadaj najpierw szersze, bardziej ogólne pytanie, aby aktywować odpowiednie koncepcje, a następnie użyj tej odpowiedzi jako kontekstu dla konkretnego pytania. Pomaga LLM zastosować ogólne zasady do rozwiązywania złożonych problemów.",
  "educationP9Title": "Chain of Thought (CoT):",
  "educationP9Text": "Poproś LLM o wyjaśnienie swojego rozumowania krok po kroku przed podaniem ostatecznej odpowiedzi (np. dodaj 'Pomyślmy krok po kroku.'). Poprawia wydajność w zadaniach wymagających logiki, obliczeń lub wieloetapowej dedukcji.",
  "educationP10Title": "Self-Consistency:",
  "educationP10Text": "Wygeneruj wiele ciągów myślowych (CoT) dla tego samego promptu (często używając wyższej temperatury) i wybierz najczęstszą ostateczną odpowiedź. Poprawia solidność i dokładność, zwłaszcza w złożonych zadaniach rozumowania.",
  "educationP11Title": "Tree of Thoughts (ToT):",
  "educationP11Text": "Pozwala LLM na jednoczesne eksplorowanie wielu ścieżek rozumowania, oceniając pośrednie kroki jak gałęzie na drzewie. Przydatne w bardzo złożonych problemach wymagających eksploracji i strategicznego myślenia.",
  "summaryText": "Podsumowanie Twojej gry pojawi się tutaj..."
}
